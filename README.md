# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #3 выполнил:
- Казанцев Михаил Максимович
- РИ-210914
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | # | - |
| Задание 2 | # | - |
| Задание 3 | # | - |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
-

## Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения.
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения.
- Задание 3.
- Код реализации выполнения задания.
- Выводы.

## Цель работы
Познакомиться с программными средствами для создания системы машинного обучения и ее интеграции в Unity.

## Задание 1
Ход работы:
- Сначала был установлен пакет ML Agents для Unity
- После этого список пакетов выглядит вот так:
- 
![packages](images/packages.png?raw=true)

- Затем была произведена настройка Python
- Среда разработки PyCharm была использована как визуальная обёртка над venv, чтобы модули не устанавливались глобально для всей машины

![python_install](images/python_install.png?raw=true)

- В Unity была создана следующая структура:

![setup1_1](images/setup1_1.png?raw=true)

	* Environment - просто объект-контейнер
	* Floor - просто плоскость
	* Target - просто куб
	* Agent - агент машинного обучения, он содержит следующие компоненты:

![setup1_2](images/setup1_2.png?raw=true)

- Код компонента RollerAgent:

![roller_code](images/roller_code.png?raw=true)

- Копии модели были сделаны при помощи компонента Instancer

![instancer_props](images/instancer_props.png?raw=true)
![instancer_code](images/instancer_code.png?raw=true)

- Теперь можно запускать `mlagents-learn`:

![mlagents_launch](images/mlagents_launch.png?raw=true)

- Процесс обучения:
![instancer_result](images/instancer_result.png?raw=true)


- Результаты модели после обучения:

https://user-images.githubusercontent.com/21042695/197859692-c57c416f-17fa-4453-a43e-e6ff36a1a970.mp4

[ВИДЕО](images/testing_inference.mp4)

- Как видно, благодаря фреймворку Unity MLAgents обучение нейронных сетей в сложных играх/окружениях становится намного доступней

## Задание 2
### Подробно опишите каждую строку файла конфигурации нейронной сети `rollerball_config.yaml`. Самостоятельно найдите информацию о компонентах Decision Requester, Behavior Parameters, добавленных на сфере.

![config_breakdown.png](images/config_breakdown.png?raw=true)

- Decision Requester - заставляет агента принимать решения каждые `Decision Period` кадров

- Behavior Parameters - определяет как агент передаёт данные модели и какие действия модель может выполнять. Так же отвечает за выполнение натренированной модели без соединение с Python

## Задание 3
### Доработайте сцену и обучите ML-Agent таким образом, чтобы шар перемещался между двумя кубами разного цвета. Кубы должны, как и в первом задании, случайно изменять координаты на плоскости.

- Внесём небольшие изменения в файл RollerAgent(новая версия - [RollerAgentMultiTarget](MLAgentsTest/Assets/Scripts/RollerAgentMultiTarget.cs))

![roller_code2](images/roller_code2.png?raw=true)

- Вместо одной, агент теперь хранит ссылки на несколько целей

- Также, он хранит индекс текущуей цели. Там, где в оригинале использовался `Target`, теперь используется цель по текущему индексу

- Когда агент достигает текущей цели, индекс увеличивается на 1

- Когда все цели были удачно пройдены, и индекс выходит за границы массива, мы награждаем агента и передвигаем все цели

- Даже после этих изменений, модель, обученная для Задания 1, справляется и с этим заданием

https://user-images.githubusercontent.com/21042695/197859977-83118793-74c5-4228-8515-cc3e5a07c6f6.mp4

[ВИДЕО](images/testing_inference2.mp4)

## Выводы
### Игровой баланс
- Чтобы быть интересной, игра должна предоставлять испытания игроку. При этом, испытания не должны быть слишком сложными - мало кто будет играть в игру, которую невозможно пройти. Но испытания и не должны быть слишком лёгкими - иначе игра просто станет скучной
- Это и есть суть игрового баланса

- Системы машинного обучения могут помочь найти этот баланс
- Они могут играть 24/7, тем самым получая больше опыта чем любой реальный игрок(возможно даже до релиза!)
- Кроме того, эти системы очень хороши в нахождении багов - есть даже целая [таблица](http://tinyurl.com/specification-gaming) с разными проектами где модели научились использовать баги в свою пользу
- И благодаря таким фреймворкам как Unity MLAgents, подключить такую систему к реальной игре становится всё проще и проще

### Остальные выводы
- Я освоил основы фреймворка Unity MLAgents
- научил нейронную сеть действовать в простом физическом окружении
- изучил основы современных алгоритмов в сфере reinforcement learning

## Код и другие ресурсы
- Проект Unity находится в папке [MLAgentsTest](MLAgentsTest) этого репозитория
